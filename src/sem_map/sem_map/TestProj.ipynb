{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rclpy.node import Node\n",
    "from sensor_msgs.msg import Image\n",
    "from cv_bridge import CvBridge\n",
    "import cv2\n",
    "from PIL import Image as PILImage, PngImagePlugin\n",
    "import io\n",
    "\n",
    "class ImageSubscriber(Node):\n",
    "    def __init__(self):\n",
    "        super().__init__('image_subscriber')\n",
    "        self.subscription = self.create_subscription(\n",
    "            Image,\n",
    "            '/camera/camera/color/image_raw',  # Change this to your image topic\n",
    "            self.image_callback,\n",
    "            10)\n",
    "        self.subscription  # prevent unused variable warning\n",
    "        self.bridge = CvBridge()\n",
    "        self.pil_image = None\n",
    "        self.cv_image = None\n",
    "        self.png_image = None\n",
    "\n",
    "    def image_callback(self, msg):\n",
    "        cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')\n",
    "        rgb_image = cv2.cvtColor(cv_image,cv2.COLOR_BGR2RGB)\n",
    "        self.cv_image = rgb_image  # Store OpenCV image for later use\n",
    "        self.pil_image = PILImage.fromarray(cv_image)\n",
    "\n",
    "        # buffer = io.BytesIO()\n",
    "        # self.pil_image.save(buffer, format='PNG')\n",
    "\n",
    "        # buffer.seek(0)\n",
    "        # self.png_image = PngImagePlugin.PngImageFile(buffer)\n",
    "\n",
    "        # cv2.imshow(\"Image Window\", self.cv_image)\n",
    "        # cv2.waitKey(100)  # Wait for a key press for 1 millisecond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import rclpy\n",
    "import rclpy.logging\n",
    "from rclpy.executors import MultiThreadedExecutor\n",
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "rclpy.init(args=None)\n",
    "image_subscriber = ImageSubscriber()\n",
    "\n",
    "from utils import *\n",
    "rscalc = RealSensePointCalculator()\n",
    "\n",
    "executor = MultiThreadedExecutor()\n",
    "executor.add_node(image_subscriber)\n",
    "executor.add_node(rscalc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    while rclpy.ok():\n",
    "        print(1)\n",
    "        executor.spin_once(timeout_sec=0.1)\n",
    "        if image_subscriber.pil_image is not None:\n",
    "            print(2)\n",
    "            pil_image = image_subscriber.pil_image\n",
    "            if rscalc.info_received():\n",
    "                break\n",
    "        time.sleep(0.1)\n",
    "        print(3)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "finally:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscalc.depth_image == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pil_image.size)\n",
    "# display the image using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(pil_image)\n",
    "# plt.imshow(image[0].permute(1, 2, 0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running this, add lang-seg folder to your python path\n",
    "from LoadLSeg import *\n",
    "import torchvision.transforms as transforms\n",
    "# from PIL import Image # use PILImage instead\n",
    "from test_lseg_zs import *\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(480),           # Resize the shorter side to 480 while maintaining aspect ratio\n",
    "    transforms.CenterCrop((480, 480)),  # Crop the center to 480x480\n",
    "    transforms.ToTensor()            # Convert to tensor\n",
    "])\n",
    "\n",
    "image_tensor = transform(pil_image)\n",
    "image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_tensor.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "with torch.no_grad():\n",
    "    feat = model(image_tensor.unsqueeze(0).cuda())\n",
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = \"blue bottle\"\n",
    "threshold = 0.99\n",
    "text_feat1 = model.encode_text(search)\n",
    "sim_image = feat.half() @ text_feat1.t()\n",
    "sim_image[sim_image < sim_image.max()*threshold] = 0\n",
    "display_img2 = sim_image.detach().cpu().numpy()\n",
    "plt.imshow(display_img2, cmap='gray', vmin=display_img2.min(), vmax=display_img2.max())\n",
    "# coordinates of the maximum value in the similarity image\n",
    "print(\"###############################################\")\n",
    "print(f\"searching for: {search}\")\n",
    "print(\"###############################################\")\n",
    "x, y = float((sim_image.argmax() // sim_image.shape[1]).detach().cpu()), float((sim_image.argmax() % sim_image.shape[1]).detach().cpu())\n",
    "print(\"max value at (coordinate in pixel):\", f\"row {x}\", f\"col {y}\")\n",
    "print(\"max value at (coordinate %):\", round(x/480,2), round(y/480, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(feat_image[350, 350])\n",
    "# print(feat_image.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_image = PCA_and_Cluster(feat)\n",
    "plt.imshow(clustered_image, cmap='gray', vmin=clustered_image.min(), vmax=clustered_image.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_pixels = obtain_key_pixels(feat, clustered_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(key_pixels))\n",
    "# print(len(key_pixels[19][1][0]))\n",
    "# print(key_pixels[19])\n",
    "for feature, pixels in key_pixels:\n",
    "    if len(pixels[0]) > 10:\n",
    "        print(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look = None\n",
    "for feat_mean, pixels in key_pixels:\n",
    "    look = pixels[0][1]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(rscalc.intrinsics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_points = []\n",
    "for feat_mean, pixels in key_pixels:\n",
    "    points = []\n",
    "    for i in range(len(pixels[0])):\n",
    "        point = rscalc.calculate_point(float(pixels[0][i]), float(pixels[1][i]))\n",
    "        points.append(point)\n",
    "    point_mean = np.mean(points, axis=0)\n",
    "    key_points.append((feat_mean, point_mean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_points = rscalc.obtain_key_points(key_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = min(30, len(class_pixel[0]))\n",
    "indices = np.random.choice(len(class_pixel[0]), n, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "executor.shutdown()\n",
    "image_subscriber.destroy_node()\n",
    "rscalc.destroy_node()\n",
    "rclpy.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
